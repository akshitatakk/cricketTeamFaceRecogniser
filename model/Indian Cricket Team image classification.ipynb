{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('C:/Users/Akshay/Desktop/faceRecognition/model/open_cv/haarcascade_frontalface_default.xml')\n",
    "eye_cascade  = cv2.CascadeClassifier('C:/Users/Akshay/Desktop/faceRecognition/model/open_cv/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        if len(eyes) >= 2:\n",
    "            return roi_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"C:/Users/Akshay/Desktop/faceRecognition/model/dataset/\"\n",
    "path_to_cr_data = \"C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        img_dirs.append(entry.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/Akshay/Desktop/faceRecognition/model/dataset/Hardik_Pandya',\n",
       " 'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/KL_Rahul',\n",
       " 'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/MS_Dhoni',\n",
       " 'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/Rohit_Sharma',\n",
       " 'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/Virat_Kohli']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "if os.path.exists(path_to_cr_data):\n",
    "     shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardik_Pandya\n",
      "Generating cropped images in folder:  C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya\n",
      "KL_Rahul\n",
      "Generating cropped images in folder:  C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul\n",
      "MS_Dhoni\n",
      "Generating cropped images in folder:  C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni\n",
      "Rohit_Sharma\n",
      "Generating cropped images in folder:  C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma\n",
      "Virat_Kohli\n",
      "Generating cropped images in folder:  C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli\n"
     ]
    }
   ],
   "source": [
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    print(celebrity_name)\n",
    "    \n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    \n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "                \n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name \n",
    "            \n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pywt\n",
    "import cv2\n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #converting to grayscale\n",
    "    imArray = cv2.cvtColor(imArray, cv2.COLOR_RGB2GRAY)\n",
    "    #converting to float\n",
    "    imArray = np.float32(imArray)\n",
    "    imArray/= 255;\n",
    "    #compute coefficients\n",
    "    coeffs = pywt.wavedec2(imArray, mode, level=level)\n",
    "    \n",
    "    #processing coefficients\n",
    "    coeffs_H = list(coeffs)\n",
    "    coeffs_H[0] *= 255;\n",
    "    \n",
    "    #reconstruction\n",
    "    imArray_H = pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H = np.uint8(imArray_H)\n",
    "    \n",
    "    return imArray_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hardik_Pandya': ['C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya1.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya2.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya3.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya4.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya5.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya6.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya7.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya8.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya9.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya10.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya11.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya12.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya13.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya14.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya15.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya16.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya17.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya18.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya19.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya20.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya21.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya22.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya23.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya24.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya25.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya26.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya27.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya28.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya29.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya30.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya31.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya32.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya33.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya34.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya35.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya36.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya37.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya38.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya39.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya40.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya41.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya42.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya43.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya44.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya45.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya46.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya47.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya48.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya49.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya50.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya51.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya52.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya53.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya54.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya55.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Hardik_Pandya/Hardik_Pandya56.png'],\n",
       " 'KL_Rahul': ['C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul1.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul2.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul3.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul4.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul5.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul6.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul7.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul8.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul9.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul10.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul11.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul12.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul13.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul14.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul15.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul16.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul17.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul18.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul19.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul20.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul21.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul22.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul23.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul24.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul25.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul26.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul27.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul28.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul29.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul30.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul31.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul32.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul33.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul34.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul35.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul36.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul37.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul38.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul39.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul40.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul41.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul42.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul43.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul44.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul45.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul46.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul47.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul48.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul49.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/KL_Rahul/KL_Rahul50.png'],\n",
       " 'MS_Dhoni': ['C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni1.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni2.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni3.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni4.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni5.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni6.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni7.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni8.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni9.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni10.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni11.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni12.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni13.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni14.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni15.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni16.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni17.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni18.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni19.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni20.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni21.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni22.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni23.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni24.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni25.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni26.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni27.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/MS_Dhoni/MS_Dhoni28.png'],\n",
       " 'Rohit_Sharma': ['C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma1.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma2.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma3.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma4.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma5.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma6.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma7.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma8.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma9.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma10.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma11.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma12.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma13.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma14.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma15.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma16.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma17.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma18.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma19.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma20.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma21.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma22.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Rohit_Sharma/Rohit_Sharma23.png'],\n",
       " 'Virat_Kohli': ['C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli1.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli2.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli3.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli4.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli5.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli6.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli7.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli8.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli9.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli10.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli11.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli12.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli13.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli14.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli15.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli16.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli17.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli18.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli19.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli20.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli21.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli22.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli23.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli24.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli25.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli26.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli27.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli28.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli29.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli30.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli31.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli32.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli33.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli34.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli35.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli36.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli37.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli38.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli39.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli40.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli41.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli42.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli43.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli44.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli45.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli46.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli47.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli48.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli49.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli50.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli51.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli52.png',\n",
       "  'C:/Users/Akshay/Desktop/faceRecognition/model/dataset/cropped/Virat_Kohli/Virat_Kohli53.png']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "celebrity_file_names_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hardik_Pandya': 0,\n",
       " 'KL_Rahul': 1,\n",
       " 'MS_Dhoni': 2,\n",
       " 'Rohit_Sharma': 3,\n",
       " 'Virat_Kohli': 4}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = {}\n",
    "count = 0\n",
    "for celebrity_name in celebrity_file_names_dict.keys():\n",
    "    class_dict[celebrity_name] = count\n",
    "    count = count + 1\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =[]\n",
    "y =[]\n",
    "\n",
    "for celebrity_name, training_files in celebrity_file_names_dict.items():\n",
    "    for training_image in training_files:\n",
    "        img = cv2.imread(training_image)\n",
    "        if img is None:\n",
    "            continue\n",
    "        scalled_raw_img = cv2.resize(img,(32,32))\n",
    "        img_har =w2d(img,'db1',5)\n",
    "        scalled_image_har = cv2.resize(img_har, (32,32))\n",
    "        combined_img = np.vstack((scalled_raw_img.reshape(32*32*3,1),scalled_image_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(class_dict[celebrity_name])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 4096)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X).reshape(len(X),4096).astype(float)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5283018867924528"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC(kernel = 'rbf', C=10))])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.80      0.71        15\n",
      "           1       0.69      0.69      0.69        13\n",
      "           2       1.00      0.33      0.50         6\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.26      0.50      0.34        10\n",
      "\n",
      "    accuracy                           0.53        53\n",
      "   macro avg       0.52      0.47      0.45        53\n",
      "weighted avg       0.51      0.53      0.49        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshay\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.560484</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.420968</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.586089</td>\n",
       "      <td>{'logisticregression__C': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.560484   \n",
       "1        random_forest    0.420968   \n",
       "2  logistic_regression    0.586089   \n",
       "\n",
       "                                    best_params  \n",
       "0        {'svc__C': 1, 'svc__kernel': 'linear'}  \n",
       "1  {'randomforestclassifier__n_estimators': 10}  \n",
       "2                  {'logisticregression__C': 5}  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6226415094339622"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['svm'].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5283018867924528"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['random_forest'].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6037735849056604"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimators['logistic_regression'].score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = best_estimators['svm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test, best_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'Truth')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(cm, annot=True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\akshay\\anaconda3\\lib\\site-packages (0.14.1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['C:/Users/Akshay/Desktop/faceRecognition/model/saved_model.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install joblib\n",
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(best_clf, 'C:/Users/Akshay/Desktop/faceRecognition/model/saved_model.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"C:/Users/Akshay/Desktop/faceRecognition/model/class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(class_dict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
